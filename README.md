# ğŸ” RAG-Lite: Smart Document Q&A

A lightweight but powerful implementation of Retrieval Augmented Generation (RAG) with hierarchical document chunking and evidence-based responses.

## âœ¨ Key Features

### ğŸ“š Smart Document Processing
- ğŸ¯ Hierarchical chunking based on document structure
- ğŸ“‘ Preserves section headings and document hierarchy
- ğŸ”„ Automatic duplicate detection for multiple uploads
- ğŸ’¾ Smart caching system for processed documents

### ğŸ§  Intelligent Retrieval
- ğŸ¯ Dynamic similarity threshold adjustment
- ğŸ” Configurable top-K retrieval
- ğŸ“Š Cosine similarity for semantic matching
- ğŸ·ï¸ Section-aware chunk identification

### ğŸ¤– Advanced Response Generation
- ğŸ“ Evidence-based responses with source citations
- ğŸ” References to specific document sections
- ğŸ¨ Clean and intuitive chat interface
- ğŸ“ˆ Token estimation and optimization

### ğŸ› ï¸ Technical Features
- ğŸ”’ Type-safe implementation with dataclasses
- ğŸ§ª Testable architecture with dependency injection
- ğŸ“¦ Efficient caching and state management
- ğŸš€ Streamlit-powered responsive UI

## ğŸš€ Installation

1. **Clone the Repository**
   ```bash
   git clone https://github.com/yourusername/rag-lite.git
   cd rag-lite
   ```

2. **Set Up Python Environment**
   ```bash
   python -m venv .venv
   source .venv/bin/activate  # On Windows: .venv\Scripts\activate
   ```

3. **Install Dependencies**
   ```bash
   uv pip install -e .
   ```

4. **Install System Dependencies**
   - Install Pandoc for document conversion:
     ```bash
     # macOS
     brew install pandoc

     # Ubuntu/Debian
     sudo apt-get install pandoc

     # Windows
     choco install pandoc
     ```

5. **Set Up Environment Variables**
   ```bash
   cp env.template .env
   # Edit .env and add your OpenAI API and AWS keys
   ```

## ğŸ® Usage

1. **Start the Application**
   ```bash
   streamlit run rag-lite/app.py
   ```

2. **Upload Documents**
   - ğŸ“‚ Click the file upload button in the sidebar
   - ğŸ“„ Upload any DOCX file (< 2MB)
   - ğŸ”„ Watch as it's processed and chunked intelligently

3. **Configure Retrieval**
   - ğŸšï¸ Adjust "Top K Chunks" slider (1-10)
   - ğŸ¯ Set "Similarity Threshold" (0.0-1.0)
   - ğŸ’¡ Higher threshold = more relevant but fewer results

4. **Ask Questions**
   - â“ Type your question in the chat input
   - ğŸ¤– Get responses with evidence citations
   - ğŸ“š See which sections of your documents were used

## ğŸ¯ Example Queries

```
Q: What are the main points in the introduction?
A: Based on Section 1 (Introduction), the main points are...

Q: Summarize the methodology section.
A: According to Section 3.2 (Methodology), the approach involves...
```

## ğŸ—ï¸ Project Structure

```
rag-lite/
â”œâ”€â”€ app.py              # Streamlit UI and main application
â”œâ”€â”€ parser.py           # Document parsing and chunking
â”œâ”€â”€ rag_pipeline.py     # Core RAG implementation
â”œâ”€â”€ openai_services.py  # OpenAI API integration
â””â”€â”€ logger.py           # Logging configuration
```

## ğŸ› ï¸ Advanced Configuration

### Chunking Strategy
The system uses a hierarchical chunking strategy based on document structure:
- ğŸ“‘ Respects document hierarchy (chapters, sections, subsections)
- ğŸ¯ Maintains context through section headings
- ğŸ” Preserves relationships between chunks

### Retrieval Settings
- **Top K**: Number of chunks to retrieve (default: 3)
- **Similarity Threshold**: Minimum similarity score (default: 0.6)
  - 0.8-1.0: Very strict matching
  - 0.6-0.8: Balanced retrieval
  - 0.4-0.6: More exploratory results

## ğŸ“ License

MIT License - feel free to use and modify! 